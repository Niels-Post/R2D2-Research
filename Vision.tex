%! Author = R2D2 Team 3
%! Date = 14/04/2020

% Preamble
\documentclass[11pt]{article}
\usepackage{hyperref}
\usepackage{natbib}



\title{Een methode voor pijndetectie door middel van Computer Vision, geörienteerd op embedded systemen}

\author{\emph{R2D2 Team 3} \and Otto de Visser \and Niels Post}

% Document
\begin{document}
    \maketitle

    \clearpage
    \renewcommand{\contentsname}{Inhoudsopgave}
    \tableofcontents

    \clearpage


    \section{Samenvatting}


    \section{Inleiding}
    \emph{R2D2 heeft als bedrijf als doel om multifunctionele, modulaire robots te maken voor gebruik in een rampgebied.
    Omdat in een rampgebied vaak slachtoffers zijn die door allerlei oorzaken hevige pijn hebben,
    is het belangrijk dit te indexeren, en hiernaar prioriteiten te stellen.}

    In dit onderzoek willen wij manieren vinden om door middel van Computer Vision in een klein (embedded) systeem pijnniveaus
    te detecteren.
    Vanwege mogelijke beperkte connectiviteit in een rampgebied onderzoeken wij methoden die volledig automatisch,
    zonder netwerkconnectiviteit of zware hardware kunnen werken.

    Tijdens het lezen van dit onderzoek zal de lezer in de eerste plaats meer leren over vision-algoritmes met pijn
    herkennen als doel.
    Hierbij gaan wij specifiek in op de efficiëntie,geschikte hardware, en verwerkingstijden van hardware.
    Hiernaast bespreken wij welke camera’s het meest geschikt zijn voor gebruik bij Computer Vision in het algemeen.
    Uiteindelijk kiezen wij 1 combinatie van een algoritme en camera die het best passen bij de context van een pijn
    detectie module binnen een R2D2 robot.


    Om dit onderzoek te definiëren zullen wij uit gaan van de volgende onderzoekshoofdvraag:\\

    \textbf{Hoofdvraag} \hspace{5pt} \emph{Welke computer methoden op basis van computer vision zonder gebruik van netwerkconnectiviteit high
    performance hardware bestaan er waarmee je pijn kan kwantificeren in de context van een embedded systeem?}

    \bigskip

    Deze hoofdvraag verdelen wij in de volgende 7 deelvragen:

    \begin{enumerate}
        \item \label{itm:dv1} Is het mogelijk om computer vision toe te passen op videobeeld om pijn te kunnen herkennen op het gezicht van een mens?
        \item \label{itm:dv2} Hoeveel foto’s per tijdseenheid moeten we minimaal verwerken om zeker te zijn dat we een valide uitspraak kunnen doen over het pijnniveau dat iemand ervaart?
        \item \label{itm:dv3} Wat zijn de minimale hardwarevereisten van een systeem dat pijnmetingen door middel van Computer Vision uitvoert?
        \item \label{itm:dv4} Volgt er een toename in accuraatheid uit het langer analyseren van een frame?
        \item \label{itm:dv5} Wat is de beste camera voor het toepassen van Vision algoritmes die verkrijgbaar is op de markt?
        \item \label{itm:dv6} Welke bestaande implementaties van een pijnmeting algoritme zijn er, en wat zijn de gebruiksrechten hiervan?
        \item \label{itm:dv7} Wat is de maximaal bereikbare accuraatheid en snelheid bij gebruik van boven onderzochte methoden?
    \end{enumerate}


    \section{Literatuurverkenning}
    In dit hoofdstuk verkennen we de te onderzoeken literatuur. Hierbij beschrijven wij welke informatie wij verwachten hieruit te halen.


    \section{Probleemstelling}
    Voor doktoren is het lastig om een objectief pijn vast te stellen.
    Vaak moet een patiënt zelf een getal tussen de 1 en de 10 geven voor zijn pijn.
    Echter is deze manier van pijn inschatten niet erg objectief, daarnaast is het niet
    altijd mogelijk met de patiënt te communiceren.
    In rampscenario’s zijn er bijvoorbeeld te veel slachtoffers om aan iedereen te vragen hoeveel pijn hij voelt.
    Wel is het belangrijk om te weten hoeveel pijn mensen hebben om ze met meer/minder prioriteit te helpen.
    Hierom, in combinatie met de doelen van het R2D2 bedrijf, bestaat de vraag naar een automatische module die pijn
    detecteert.


    \section{Theorie en hypothese}
    De hoofdvraag van dit onderzoek vergelijkt methoden die wij nog niet kennen voor het onderzoek. Hierom kunnen wij geen hypothese stellen voor de hoofdvraag.
    Wel kunnen wij een set kleinere hypotheses stellen, betreffende enkele deelvragen.

    \paragraph{\hyperref[itm:dv1]{Deelvraag 1}}
    Van wat wij zelf weten van pijndetectie en herkenning, is dat dit een moeilijk onderwerp is.
    Ondanks dat er universele uitingen van pijn zijn (zoals auw zeggen, en een vertrokken gezicht), is het moeilijk om vast te stellen hoe veel pijn iemand heeft.
    Doktoren vragen hierom dan ook vaak aan mensen om hun pijn een cijfer te geven.

    Onze hypothese voor deze deelvraag is dan ook:  \emph{Pijn detecteren met Vision is in algemene zin mogelijk, maar het niveau classificeren is waarschijnlijk lastig of onmogelijk}

    \paragraph{\hyperref[itm:dv3]{Deelvraag 3}}
    Wij verwachten dat de belangrijkste vereiste van een systeem een minimale hoeveelheid werkgeheugen is.
    Omdat er geen directe deadline is voor een berekening, kan een processor hier langer over doen, maar als het geheugen niet toereikend is, kan een afbeelding niet opgeslagen worden voor verwerking.

    Omdat microcontrollers vaak niet meer dan 50kB werkgeheugen hebben, verwachten wij dat de meesten geen Vision algoritmes kunnen draaien.
    De grootste limiterende factor hiervoor is dat een 16 bits processor niet meer dan +- 131 kB aan kan.
    Extern geheugen kan hierbij dus ook niet extreem veel toevoegen, aangezien dit niet kan worden geadresseerd.

    Onze hypothese is daarom: \emph{Voor een Vision-gebaseerd pijnmetingsalgoritme is een embedded systeem nodig wat minimaal een 32 bits processor heeft.}

    \paragraph{\hyperref[itm:dv4]{Deelvraag 4}}
    Bij de vision algoritmes waar wij tot nu toe in aanraking zijn geweest (Gezichtsdetectie), was de uitkomst gebaseerd op een vaste set handelingen.
    Omdat deze handelingen niet afhankelijk zijn van entropie, was het resultaat altijd hetzelfde.
    Wij denken dat de handelingen voor pijndetectie op dezelfde manier zullen werken, aangezien deze ook te maken zullen hebben met het detecteren van gezichtskenmerken.

    Voor deze deelvraag stellen wij dan ook de hypothese: \emph{Het langer analyseren van een videoframe zal geen accuratere resultaten geven bij een pijnmetingsalgoritme op basis van computer vision}

    \paragraph{\hyperref[itm:dv5]{Deelvraag 5}}
    Computer Vision algoritmes zijn hevig afhankelijk van detectie van kleuren, contrasten en randen.
    Omdat de verwerking hiervan afhankelijk zijn van het kleurpalet van de gebruikte camera, denken wij dat er camera's zullen zijn die specifiek gericht zijn op Computer Vision.
    Mogelijk gebruiken deze camera's geen RGB, maar bijvoorbeeld een aRGB kleurenschema.

    Wij stellen hiervoor de hypothese: \emph{Er zijn camera's op de markt beschikbaar die specifiek gericht zijn op Computer Vision algoritmes}


    \section{Begrippenlijst}
    \begin{tabular}{p{10em} p{21em}}
        \textbf{Computer Vision} & Een algemene term voor algoritmes die gebruik maken van camerabeelden, en hier conclusies uit trekken\\

    \end{tabular}


    \section{Uitvoering}

    Voor \emph{\hyperref[itm:dv1]{deelvraag 1}} tot en met \emph{\hyperref[itm:dv4]{deelvraag 4}} zullen wij een literatuuronderzoek
    verrichten naar methoden van pijndetectie door middel van Vision.
    Hierbij zullen wij per methode de deelvragen beantwoorden, om zo uiteindelijk een conclusie te kunnen trekken over
    de meest geschikte methode(n).
    Het is belangrijk om hierbij te vermelden dat het aangeven van de hardware-vereisten
    zal gebeuren op basis van een schatting.
    Hierbij kijken we vooral naar het geheugengebruik van de methode,
    aangezien dit de meest limiterende factor is van een embedded systeem.


    Voor \emph{\hyperref[itm:dv1]{deelvraag 5}} doen wij een vergelijkend onderzoek voor camera's.
    We onderzoeken het bestaan van camera's specifiek voor vision, en noteren specificaties van deze camera's.
    Bij dit onderzoek betrekken wij ook een webcam en een actiecamera.


    Voor deelvraag 6 doen wij experimenteel onderzoek.
    Door meerdere implementaties te vergelijken, kunnen wij de maximale bereikbare waarden ervan vergelijken.


    \section{Resultaten}

    \subsection{Onderzoek methoden pain detection}

    \subsubsection{Methode 1}

    \emph{\citet{werner2014automatic}} Automatic pain recognition from video and biomedical signals\\
    \emph{\citet{prkachin1992consistency}} The consistency of facial expressions of pain: a comparison across modalities\\
    Deze methode combineert het gebruik van Vision algoritmen, met het meten van biomedische data door middel van sensoren.
    Wij zullen hier alleen kijken naar het gedeelte van de methode met betrekking tot Vision.

    \paragraph{Aantal foto's per tijdseenheid}
    Deze methode maakt gebruik van veranderingen in gezichtsafstanden ten opzichte van een baseline, en kan dus met 2 foto's een resultaat geven.
    Deze foto's hoeven dan ook niet extreem snel verwerkt te worden, en het systeem mag hier een aantal seconden over doen.

    \paragraph{Hardware-vereisten}
    De vereisten voor de berekening zelf zijn weinig: Er moeten slechts een aantal afstanden van coordinaten vergeleken worden.
    Dit zullen de meeste microcontrollers ook kunnen.
    Het probleem zit hierom meer in de methode van facial feature detection.
    Afhankelijk van de gebruikte methode, moet de processor mogelijk meerdere kleurafbeeldingen opslaan, of zware convoluties doen.
    Hierom verwachten wij dat deze methode niet gedraaid kan worden op een microcontroller.

    \paragraph{Langer analyseren frame}
    Of pijn accurater gedetecteerd kan worden is grotendeels afhankelijk van de gebruikte methode voor facial feature recognition.
    Het langer analyseren kan wel effect hebben op de afstand waarop pijn gedetecteerd kan worden.
    Dit zou mogelijk zijn door de afbeelding op volledige resolutie te verwerken, en niet omlaag te schalen.


    \section{Conclusie en Discussie}
    Test \citet{werner2014automatic}


    \section{Evaluatie}


    \section{Aanbevelingen}


    \section{Suggesties voor verder onderzoek}


    \section{Literatuur}


    \section{Bijlagen}

    \subsection{Invullingen onderzoek}

    \subsubsection{Methode 1}
    \emph{\citet{werner2014automatic} Automatic pain recognition from video and biomedical signals}

    \paragraph{Korte Omschrijving}
    Het paper omschrijft een bredere methode, maar wij leggen de focus op het gedeelte vision.
    Deze methode detecteert pijn door te kijken naar de positie van bepaalde gezichtseigenschappen ten opzichte van elkaar.
    Zo kan pijn zich bijvoorbeeld uiten in een “samengetrokken” gezicht.

    \paragraph{Van welk principe maakt het gebruik?}
    Relationele positie van gezichtseigenschappen

    \paragraph{Geschatte piek-geheugengebruik per meting}
    Wij gaan uit van een ruime minimum voor gezichtsdetectie.
    Gezichtsdetectie en herkenning functioneren beduidend minder onder een resolutie van 50x50 pixels \citet{boom2006effect}.
    Hier gaan wij dan ook vanuit bij het geheugengebruik.
    Een afbeelding van 50x50 gebruikt +- 7.5kB in ruimte.

    Methoden van facedetection zijn ons niet bekend, hierom is dit moeilijk in te schatten.
    Ervanuitgaande dat er convolutie-operaties uitgevoerd worden op de afbeelding zal de afbeelding hoogst waarschijnlijk op momenten meerdere keren in het geheugen moeten bestaand.
    Hiernaast moet de draaiende programmacode, en eventuele image kernels toegevoegd worden.
    In piek zal dit programma minimaal 50 kB geheugen gebruiken, maar naar alle waarschijnlijkheid meer.

    \paragraph{Geschatte tijdsduur voor 1 conclusie}
    Wij denken dat er minimaal 2 metingen gedaan moeten worden.
    Dit omdat het gezicht vergeleken moet worden, en de samentrekking van het gezicht ten opzichte van de eerste meting bepaald moet worden.

    Op een adequate computer hoeft een meting niet veel langer te duren dan 0,1 seconde.
    Twee metingen zouden dan zo’n 0.2 seconden duren.

    \paragraph{Embedded capaciteit}
    Zoals wij al enigszins hadden verwacht is het niet redelijkerwijs mogelijk dit te draaien op een Arduino.
    Dit is voornamelijk omdat het piek-geheugengebruik te groot is hiervoor.
    Wel is dit prima mogelijk om te draaien op een Raspberry Pi of een mini-pc.

    \paragraph{Maximale geschatte effectieve afstand}
    Dit is voornamelijk afhankelijk van de tijd die wij besteden aan het herkennen.
    In combinatie met een camera met een hoge resolutie kunnen afstanden van vele meters gehaald worden (uitgaande van een minimum gezichtsgrootte van 50pxx50px.
    Hiervoor zou een face detection algoritme wel erg vaak/erg precies uitgevoerd worden, wat de verwerkingstijd flink vergroot.
    De maximale afstand is in dit geval dus afhankelijk van de maximale verwerkingstijd

    \paragraph{Kosten vereiste specifieke apparatuur}
    Voor deze methode is alleen een (mini)-pc en een camera vereist.
    Een (minimale) combinatie van een Raspberry Pi (€40) en een standaard webcam(€30) zou ongeveer €70,- kosten.

    \paragraph{Haalbaarheid}
    Wij denken dat deze methode voor onze scope haalbaar is, met een paar aanpassingen:
    \begin{itemize}
        \item Deze methode projecteert gezichtseigenschappen op een 3d-model van een gezicht. Hier hebben wij noch ervaring, noch tijd voor om uit te werken.
        Om dit te vermijden zouden wij de aanname doen dat iemand recht in de camera kijkt.
        Zo kunnen wij toch met zekerheid afstanden tussen gezichtseigenschappen meten.
        \item Zoals eerder aangegeven richten wij ons enkel op het vision-gedeelte van dit onderzoek, niet op de biomedische sensoren.
    \end{itemize}

    \paragraph{Mogelijke implementatie}
    Wij maken gebruik van DLib, een c++ library waar een methode voor facial feature detection in opgenomen is.
    Uit een eerste foto/meting extraheren wij een aantal afstanden tussen bepaalde gezichtskenmerken, en slaan deze op.
    Hierna doen wij steeds opnieuw metingen en vergelijken dit met de oorspronkelijke afstandsmetingen,
    hierbij kijkend naar de specifieke veranderingen zoals genoteerd in de onderzochte papers.



    \bibliographystyle{apalike}
    \bibliography{Bibliography/Main}

\end{document}


